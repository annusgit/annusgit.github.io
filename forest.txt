Title: Monitoring Forest Cover Change Patterns Using Fully Convolutional Network Over Billion Tree Tsunami Afforestation Project Regions, Pakistan

The importance of forests on Earth cannot be emphasized enough. Forests cover roughly 30% of the Earth’s surface and are home to 80% of terrestrial species of animals, plants and insects. However, due to human development activities and natural disasters, these forests and ecosystems associated with them are under significant pressure of degradation and desertification. Around 2.3 million square kilometers of world’s forest cover has been lost between 2000 and 2012 causing not only financial losses but also severely damaging associated biodiversity and ecosystems. Unlike developed countries, the developing countries do not have the resources or budgets to conduct manual surveys to monitor forest change trends for long periods and hence they rely on estimations. We have developed a reliable method based on local data for proper quantification of forest cover change by using open source tools and techniques, which will help developing countries in more accurate estimation of the forests in order to counter challenges like climate change. 

Pakistan is among the worst hit countries by forest degradation and deforestation and if appropriate measures are not taken, the country is likely to lose all of its forests in the next thirty to
fifty years. To overcome this problem, the provincial government of Khyber Pakhtunkhwa (KP) initiated
the Billion Tree Tsunami (BTT) afforestation project. We have developed a satellite based image
analysis approach to quantitatively monitor the forest cover change as a result of BTT afforestation in KP
districts of Pakistan. The method is based on State-of-the-Art deep convolution neural networks based semantic
segmentation models. The analysis is completely data driven and has been performed using Freely Available Landsat-8 satellite imagery showing an average forest cover improvement of around 39% from 2014 to 2018. The change detection results and deforestation/afforestation hotspots identified during our analysis provide important insights into the forest change trends that will help in filling gaps in policy making that is essential for ensuring sustainable management of forests in Pakistan.

Study Area:

Khyber Pakhtunkhwa (KP) is one of the five provinces in the country and has the highest land area covered with forest at provincial level. In 2014, the BTT Project was launched in response to the international Bonn Challenge by the KP government in Pakistan. The Bonn Challenge aims to restore 150 million hectares of degraded and deforested land in the world by 2020 and 350 million hectares by 2030. It was initiated by the German government and the International Union for conservation of Nature (IUCN) in 2011 and was later extended by New York declaration on Forest at the 2014 UN Climate Summit. In total, there are 25 districts in which the BTT project afforestation drives have been carried out.

Our work focused on 17 out of 25 BTT districts that had a considerable forest cover to begin with and included Hangu, Karak, Kohat, Nowshehra, Battagram, Abbottabad, Kohistan, Haripur, Tor Ghar, Mansehra, Buner, Chitral, Lower Dir, Malakand, Shangla, Swat and Upper Dir.

Deep Learning:

Firstly, deep neural networks are defined by layers and operators, such as 2D and 3D convolutions, linear dot products, etc., and they extract features from the training data automatically and hence hand-crafted features are not needed as is the case with most statistical models. This results in a high-level of abstraction in designing neural network architectures and modern deep learning frameworks such as Pytorch and Tensorflow allow such networks to be designed quickly. Secondly, deep neural networks can be fine tuned, therefore pre-trained neural network layers that were trained on other similar datasets may be used in designing newer architectures since these layers learn must faster from newer datasets and allow the whole model to converge more quickly. Our forest cover segmentation model is based on the popular deep neural network model UNet and is implemented in Pytorch framework.

A UNet is called a "U-Net" because of its U-shaped architecture [54]. The first half of the network is an encoder, a fully convolutional feature extractor network like the VGG [69] but its classification head (dot products and softmax) is removed. An encoder may be viewed as multiple modules stacked one after the other such that the input of a module feeds fromthe output of the previous one. The operators used in all modules of this encoder are CONV, BatchNorm, ReLU, andMax POOL. Four of such modules comprise the encoder of our UNet, and it is known as a four-stage encoder. The other half of the UNet, the decoder, is the mirror image of the first half, a four-stage decoder. Each module in a decoder consists of Transposed CONV operation followed by a copy-and-fuse connection between the corresponding stages of encoder and decoder. It is followed by CONVs along with BatchNorm, ReLU andMax Pool. This concatenation operation of encoder and decoder outputs allows the decoder to utilize the features extracted by the encoder at subsequent stages. The encoder (dotted square on the left) is where the input tensor is downsampled and encoded into a smaller dimensional vector. The decoder (dotted square on the right) decodes this vector and produces full resolution segmentation for the input image. Each decoder module concatenates its output with the encoder output at the corresponding stage and the final decoder tensor is passed through a convolution again followed by a softmax layer which normalizes the output probabilities for both classes at each pixel.

Unet caption:

UNet architecture developed for our work. The encoder is the set of modules to the left and the decoder is the set of modules on the right hand side. The upsampling in the decoder is done by using a transposed convolution operator with a stride of 2. The arrows indicate tensor outputs from the encoder being copied and concatenated with the transposed convolution decoder output along the depth dimension. The input to this UNet is an 18 dimensional multispectral satellite image from the KP region.

Flow Chart:

Complete flow chart of the proposed pipeline for forest cover change analysis of BTT project. Set of all images in 2015 with less than 10% cloud cover are filtered and pixel wise median values are calculated for each band to generate a composite image. This image represent clean image of the year. The paper printed map is taken as a reference and forest/non-forest data points are labelled on this clean Landsat-8 image. This small set of data points is used to train a classifier that labels all the rest of the pixels in the clean Landsat-8 image. The result of this labelling is a digitized forest cover map. Then a Unet model is trained with clean Landsat-8 district images of 2015 as input and the target labels are the digitized forest cover maps of 2015. The trained model performs inference on the clean Landsat-8 district images of 2014, 2016, 2017 and 2018, yielding a temporal series of forest cover maps.

The UNet model is trained and tested only on images from year 2015 since that is the only data for which the ground truth is available. Trained UNet model performed inference on clean images from year 2014, 2016, 2017 and 2018. These clean Landsat-8 images were created through pixel-wise median on the full series of images for one whole year for every given district under consideration.

Observations and Discussion:

The complete change detection results are given in the following table. Hangu is the only district to show a negative change in forest cover from 2014 to 2018. The rest of the districts show an increase in forestation. The effective change percentage (last column) is the percentage change in forest cover compared to the forest cover in 2014. Hence some changes are more than 100% because forest cover in 2014 was quite low. The 14-18 LP% and 14-18 GP% columns show the forest loss and gain percentages respectively. In all districts except Hangu, the forest gain pixel percentage is more than the forest loss pixel percentage, which explains the overall forest gain seen in most districts. The forest cover for all districts increases from year 2014 to 2015, then drops in 2016, then increases again in 2017 and drops below last year again in 2018 but not as much as it dropped earlier. 

Wrong predictions for forest cover maps were generated for some districts as well, particularly in Northern Pakistan. In regions like Nowshehra, Kohat, Karak, forest predictions were less than 1% for 2014 and even upto 2% forest cover prediction in 2018 led to massive change percentages, in thousands of percents with respect to 2014 forest cover. This is primarily due to the reason that the regions in upper North Pakistan are covered with snow and their Landsat-8 images had heavy cloud cover, that can lead to such noisy predictions. This is generally the problem with using deep learning for this kind of a problem, and it can be fixed by training on the same district area cross-temporally for other years as well once their ground truth is available. It should be noted that such detailed forest cover change statistics were not available for BTT project before this work and this is considered a first attempt to assess the forest cover change of BTT project at a reasonably high spatial resolution. These results, of course, are not 100% accurate since we are relying on our digitized maps accuracy and the assumption that our cross-temporal forest cover predictions are accurate enough to carry out such a study.

One artifact seen in our maps is that the percentage forest cover jumps from years 2014 to 2015, came down closer to year 2014 percentage cover again in year 2016 and then increased normally from years 2016 to 2017 and 2018. This artifact is clearly visible in the cover maps of district Chitral and district Kohistan. In our case we are constrained by the fact that only the local land cover data for year 2015 is available. Such artifacts can be resolved by cross-temporal training on labelled Landsat-8 data of multiple years i.e. 2014, and 2016-2018. Since we are relying on the data from year 2015 only (because that is the only available data) and generating forest cover maps for years 2014, and 2016-2018, then any kind of noise, such as labelling errors, seasonality effects or cloud cover taken from year 2015 data could have generated this anomaly. We surmise that this would normalize or die out asmore training data becomes available since in that case there would be a greater chance of receiving images of the same district from different years that have different seasonality effects in them even when they were cleaned by cross-temporal median filtering within one year of data. The classification model would then learn these seasonality effects alongside the classification task and would be more robust.

Future Prospects:

Map digitization. Our digitization procedure explained in Section 2.2.1 can be made more accurate. The maps we generated were based on visual inspection only so no numerical accuracies be assigned to map generation procedure. We are currently working on generating ground truth maps with multiple land cover classes in collaboration with GIS experts from Institute of Geographical Information Systems (IGIS), NUST, Pakistan.

Semantic segmentation. We investigated the use of deep learning basedUNet topology only for semantic segmentation. Newer models, such as SegNet, and Mask RCNN can be explored for more accurate forest cover map predictions.

Cross-temporal validation. We could not verify our results cross-temporally because of inavailability of data. We provided a comparison with JAXA ALOS PALSAR forest/non-forest maps for years 2015, 2016 and 2017. More accurate comparisons will be made when we have yearly ground truth data for all the years. That would also allow us to train the classification network cross-temporally for better map predictions.

Application in other problems. Multi-label land covermaps can allow the same approach to be provided with, for example, monthly multispectral image profiles from Sentinel-2 or Landsat-8 and even SAR data tomonitor the change in water bodies, glaciers, yearly urban growth, etc.